{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_MANHATTAN_INPUT_PATH = r\"\"\n",
    "CSV_EUCLIDEAN_INPUT_PATH = r\"\"\n",
    "\n",
    "x_train_m = pd.read_csv(CSV_MANHATTAN_INPUT_PATH +\n",
    "                        r\"\\train.csv\", header=None)\n",
    "x_val_m = pd.read_csv(CSV_MANHATTAN_INPUT_PATH +\n",
    "                      r\"\\val.csv\", header=None)\n",
    "x_test_m = pd.read_csv(CSV_MANHATTAN_INPUT_PATH +\n",
    "                       r\"\\test.csv\", header=None)\n",
    "y_train_m = x_train_m.iloc[:, 0]\n",
    "x_train_m = x_train_m.drop(0, axis=1)\n",
    "y_val_m = x_val_m.iloc[:, 0]\n",
    "x_val_m = x_val_m.drop(0, axis=1)\n",
    "y_test_m = x_test_m.iloc[:, 0]\n",
    "x_test_m = x_test_m.drop(0, axis=1)\n",
    "\n",
    "cv = [([*range(0, y_train_m.shape[0])],\n",
    "       [*range(y_train_m.shape[0], y_train_m.shape[0] + y_val_m.shape[0])])]\n",
    "\n",
    "y_train_m = np.concatenate((y_train_m, y_val_m), axis=0, dtype=np.int32)\n",
    "x_train_m = np.concatenate(\n",
    "    (x_train_m, x_val_m), axis=0, dtype=np.float32)\n",
    "y_test_m = y_test_m.to_numpy(np.int32)\n",
    "x_test_m = x_test_m.to_numpy(np.float32)\n",
    "\n",
    "\n",
    "x_train_e = pd.read_csv(CSV_EUCLIDEAN_INPUT_PATH +\n",
    "                        r\"\\train.csv\", header=None)\n",
    "x_val_e = pd.read_csv(CSV_EUCLIDEAN_INPUT_PATH +\n",
    "                      r\"\\val.csv\", header=None)\n",
    "x_test_e = pd.read_csv(CSV_EUCLIDEAN_INPUT_PATH +\n",
    "                       r\"\\test.csv\", header=None)\n",
    "y_train_e = x_train_e.iloc[:, 0]\n",
    "x_train_e = x_train_e.drop(0, axis=1)\n",
    "y_val_e = x_val_e.iloc[:, 0]\n",
    "x_val_e = x_val_e.drop(0, axis=1)\n",
    "y_test_e = x_test_e.iloc[:, 0]\n",
    "x_test_e = x_test_e.drop(0, axis=1)\n",
    "\n",
    "y_train_e = np.concatenate((y_train_e, y_val_e), axis=0, dtype=np.int32)\n",
    "x_train_e = np.concatenate(\n",
    "    (x_train_e, x_val_e), axis=0, dtype=np.float32)\n",
    "y_test_e = y_test_e.to_numpy(np.int32)\n",
    "x_test_e = x_test_e.to_numpy(np.float32)\n",
    "\n",
    "labels = np.unique(y_test_m)\n",
    "\n",
    "y_test_m = np.select([y_test_m == label for label in labels],\n",
    "                     [*range(len(labels))])\n",
    "y_train_m = np.select([y_train_m == label for label in labels], [\n",
    "    *range(len(labels))])\n",
    "\n",
    "y_test_e = np.select([y_test_e == label for label in labels],\n",
    "                     [*range(len(labels))])\n",
    "y_train_e = np.select([y_train_e == label for label in labels], [\n",
    "    *range(len(labels))])\n",
    "\n",
    "datasets = {\n",
    "    \"manhattan\": [x_train_m, y_train_m, x_test_m, y_test_m],\n",
    "    \"euclidea\": [x_train_e, y_train_e, x_test_e, y_test_e]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "EXPERIMENT_NAME = \"forest2\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "forest = RandomForestClassifier(random_state=42)\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", PCA()), (\"forest\", forest)])\n",
    "\n",
    "parameters = {\n",
    "    \"pca\": [\"passthrough\", PCA(0.95, random_state=42), PCA(0.99, random_state=42)],\n",
    "    \"forest__n_estimators\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(pipe, parameters, scoring=\"accuracy\",\n",
    "                   n_jobs=3, refit=False, cv=cv)\n",
    "for key, dataset in datasets.items():\n",
    "    with mlflow.start_run(experiment_id=experiment.experiment_id, nested=True):\n",
    "        clf.fit(dataset[0], dataset[1])\n",
    "\n",
    "        mlflow.log_param(\"dataset\", key)\n",
    "\n",
    "        for i in range(len((clf.cv_results_[\"mean_test_score\"]))):\n",
    "            with mlflow.start_run(experiment_id=experiment.experiment_id, nested=True):\n",
    "                mlflow.log_param(\"dataset\", key)\n",
    "                if (type(clf.cv_results_[\"param_pca\"][i]) == str):\n",
    "                    mlflow.log_param(\"pca\", clf.cv_results_[\"param_pca\"][i])\n",
    "                else:\n",
    "                    mlflow.log_param(\"pca\", clf.cv_results_[\n",
    "                                     \"param_pca\"][i].n_components)\n",
    "                mlflow.log_param(\"forest__n_estimators\", clf.cv_results_[\n",
    "                                 \"param_forest__n_estimators\"][i])\n",
    "                mlflow.log_metric(\"mean_fit_time\", clf.cv_results_[\n",
    "                                  \"mean_fit_time\"][i])\n",
    "                mlflow.log_metric(\"mean_score_time\", clf.cv_results_[\n",
    "                                  \"mean_score_time\"][i])\n",
    "                mlflow.log_metric(\"mean_test_score\", clf.cv_results_[\n",
    "                                  \"mean_test_score\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "\"\"\" pipe = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"pca\", \"passthrough\"),\n",
    "                (\"forest\", RandomForestClassifier(300, random_state=42))])\n",
    "\n",
    "pipe.fit(datasets[\"manhattan\"][0][:len(cv[0][0]) - 1][:],\n",
    "         datasets[\"manhattan\"][1][:len(cv[0][0]) - 1][:])\n",
    "print(pipe.score(datasets[\"manhattan\"][2], datasets[\"manhattan\"][3]))\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import os\n",
    "from joblib import dump\n",
    "\n",
    "MODEL__PATH = r\"\"\n",
    "\n",
    "\n",
    "version = \"v1.1\"\n",
    "\n",
    "os.chdir(MODEL__PATH.format(type=type, version=version))\n",
    "dump(pipe, \"filename.joblib\")\n",
    " \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2dcb512a14c7d49ce34f8f8f62c46fae7107524fb2d4d624362cf2d61c94d296"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
